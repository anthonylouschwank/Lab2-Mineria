{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mineria de datos\n",
    "# Laboratorio 2\n",
    "# Anggelie Velasquez 221181\n",
    "# Anthony Lou 23410\n",
    "# Isabella Obando 23074\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homePage</th>\n",
       "      <th>productionCompany</th>\n",
       "      <th>productionCompanyCountry</th>\n",
       "      <th>productionCountry</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>video</th>\n",
       "      <th>...</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>voteAvg</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>genresAmount</th>\n",
       "      <th>productionCoAmount</th>\n",
       "      <th>productionCountriesAmount</th>\n",
       "      <th>actorsAmount</th>\n",
       "      <th>castWomenAmount</th>\n",
       "      <th>castMenAmount</th>\n",
       "      <th>releaseYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1627085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Drama|Crime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1626914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1626898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1626808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thriller|Mystery|Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1626678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2026.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  budget                        genres homePage productionCompany  \\\n",
       "0  1627085     0.0                   Drama|Crime      NaN               NaN   \n",
       "1  1626914     0.0                     Animation      NaN               NaN   \n",
       "2  1626898     0.0                     Animation      NaN               NaN   \n",
       "3  1626808     0.0  Thriller|Mystery|Documentary      NaN               NaN   \n",
       "4  1626678     0.0                     Animation      NaN               NaN   \n",
       "\n",
       "  productionCompanyCountry productionCountry  revenue  runtime  video  ...  \\\n",
       "0                      NaN               NaN      0.0       95  False  ...   \n",
       "1                      NaN               NaN      0.0        3  False  ...   \n",
       "2                      NaN               NaN      0.0        2  False  ...   \n",
       "3                      NaN               NaN      0.0        5  False  ...   \n",
       "4                      NaN               NaN      0.0       12  False  ...   \n",
       "\n",
       "  releaseDate voteAvg voteCount genresAmount productionCoAmount  \\\n",
       "0  2026-02-01     0.0         0            2                  0   \n",
       "1  2026-02-01     0.0         0            1                  0   \n",
       "2  2026-02-01     0.0         0            1                  0   \n",
       "3  2026-02-01     0.0         0            3                  0   \n",
       "4  2026-02-01     0.0         0            1                  0   \n",
       "\n",
       "  productionCountriesAmount actorsAmount  castWomenAmount castMenAmount  \\\n",
       "0                         0            8              2.0           5.0   \n",
       "1                         0            4              0.0           0.0   \n",
       "2                         0            3              0.0           0.0   \n",
       "3                         0            7              0.0           0.0   \n",
       "4                         0            3              0.0           0.0   \n",
       "\n",
       "   releaseYear  \n",
       "0       2026.0  \n",
       "1       2026.0  \n",
       "2       2026.0  \n",
       "3       2026.0  \n",
       "4       2026.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movies_2026.csv\", encoding=\"latin1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'budget', 'genres', 'homePage', 'productionCompany',\n",
       "       'productionCompanyCountry', 'productionCountry', 'revenue', 'runtime',\n",
       "       'video', 'director', 'actors', 'actorsPopularity', 'actorsCharacter',\n",
       "       'originalTitle', 'title', 'originalLanguage', 'popularity',\n",
       "       'releaseDate', 'voteAvg', 'voteCount', 'genresAmount',\n",
       "       'productionCoAmount', 'productionCountriesAmount', 'actorsAmount',\n",
       "       'castWomenAmount', 'castMenAmount', 'releaseYear'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_2026.csv\", encoding=\"latin1\")\n",
    "\n",
    "df_cluster = df.drop(columns=[\n",
    "    'id', 'genres', 'homePage', 'productionCompany',\n",
    "    'productionCompanyCountry', 'productionCountry',\n",
    "    'director', 'actors', 'actorsCharacter',\n",
    "    'originalTitle', 'title', 'originalLanguage',\n",
    "    'releaseDate', 'video',\n",
    "    'budget', 'revenue',\n",
    "    'actorsAmount', 'castWomenAmount', 'castMenAmount', 'actorsPopularity'\n",
    "], errors='ignore')\n",
    "\n",
    "df_cluster = df_cluster.select_dtypes(include=['int64','float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runtime                      0\n",
       "popularity                   0\n",
       "voteAvg                      0\n",
       "voteCount                    0\n",
       "genresAmount                 0\n",
       "productionCoAmount           0\n",
       "productionCountriesAmount    0\n",
       "releaseYear                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan)\n",
    "df_cluster = df_cluster.fillna(df_cluster.median(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.drop(columns=['budget','revenue'], errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar ceros en runtime con la mediana\n",
    "median_runtime = df_cluster.loc[df_cluster['runtime'] > 0, 'runtime'].median()\n",
    "df_cluster.loc[df_cluster['runtime'] == 0, 'runtime'] = median_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminaron las columnas de budget y revenue ya que tenian muchos datos en 0, no se van a tomar en cuenta en el clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones logaritmicas para reducir sesgo\n",
    "df_cluster['popularity'] = np.log1p(df_cluster['popularity'])\n",
    "df_cluster['voteCount'] = np.log1p(df_cluster['voteCount'])\n",
    "df_cluster['productionCoAmount'] = np.log1p(df_cluster['productionCoAmount'])\n",
    "df_cluster['productionCountriesAmount'] = np.log1p(df_cluster['productionCountriesAmount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_percentage = (df_cluster == 0).mean() * 100\n",
    "zeros_percentage = zeros_percentage.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=zeros_percentage.values, y=zeros_percentage.index)\n",
    "plt.axvline(x=20, color='red', linestyle='--', label='Umbral 20%')\n",
    "plt.xlabel(\"Porcentaje de valores en 0 (%)\")\n",
    "plt.ylabel(\"Variables\")\n",
    "plt.title(\"Porcentaje de valores en 0 por variable\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadístico de Hopkins: 0.9687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "def hopkins(X):\n",
    "    n, d = X.shape\n",
    "    m = int(0.05 * n)\n",
    "    nbrs = NearestNeighbors(n_neighbors=2).fit(X)\n",
    "    rand_X = np.random.uniform(np.min(X, axis=0), np.max(X, axis=0), (m, d))\n",
    "    u_dist, w_dist = [], []\n",
    "    for j in range(m):\n",
    "        u = rand_X[j].reshape(1, -1)\n",
    "        w = X[np.random.randint(0, n)].reshape(1, -1)\n",
    "        u_dist.append(nbrs.kneighbors(u, 2, return_distance=True)[0][0][1])\n",
    "        w_dist.append(nbrs.kneighbors(w, 2, return_distance=True)[0][0][1])\n",
    "    return np.sum(u_dist) / (np.sum(u_dist) + np.sum(w_dist))\n",
    "\n",
    "print(f\"Estadístico de Hopkins: {hopkins(X_scaled):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inertia = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel(\"Número de Clusters\")\n",
    "plt.ylabel(\"Inercia\")\n",
    "plt.title(\"Método del Codo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "df_cluster['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score (K=3): 0.3282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "sil_score = silhouette_score(X_scaled, clusters)\n",
    "print(f\"Silhouette Score (K=3): {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>voteAvg</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>genresAmount</th>\n",
       "      <th>productionCoAmount</th>\n",
       "      <th>productionCountriesAmount</th>\n",
       "      <th>releaseYear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.291979</td>\n",
       "      <td>0.105104</td>\n",
       "      <td>0.834917</td>\n",
       "      <td>0.086877</td>\n",
       "      <td>1.198105</td>\n",
       "      <td>0.292530</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>2025.169017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.655874</td>\n",
       "      <td>3.310728</td>\n",
       "      <td>6.509777</td>\n",
       "      <td>5.900776</td>\n",
       "      <td>2.613327</td>\n",
       "      <td>1.309270</td>\n",
       "      <td>0.884092</td>\n",
       "      <td>2008.801185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.020518</td>\n",
       "      <td>0.242783</td>\n",
       "      <td>1.257823</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>1.312943</td>\n",
       "      <td>0.495228</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>2025.160307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            runtime  popularity   voteAvg  voteCount  genresAmount  \\\n",
       "Cluster                                                              \n",
       "0         14.291979    0.105104  0.834917   0.086877      1.198105   \n",
       "1        101.655874    3.310728  6.509777   5.900776      2.613327   \n",
       "2         93.020518    0.242783  1.257823   0.189858      1.312943   \n",
       "\n",
       "         productionCoAmount  productionCountriesAmount  releaseYear  \n",
       "Cluster                                                              \n",
       "0                  0.292530                   0.423400  2025.169017  \n",
       "1                  1.309270                   0.884092  2008.801185  \n",
       "2                  0.495228                   0.480952  2025.160307  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.groupby(\"Cluster\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza explicada: [0.58052619 0.10184872]\n",
      "Varianza acumulada: 0.6823749150275165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_viz = PCA(n_components=2)\n",
    "X_pca_viz = pca_viz.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Varianza explicada:\", pca_viz.explained_variance_ratio_)\n",
    "print(\"Varianza acumulada:\", sum(pca_viz.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x=X_pca_viz[:,0], y=X_pca_viz[:,1],\n",
    "    hue=df_cluster[\"Cluster\"], palette=\"Set1\"\n",
    ")\n",
    "plt.title(\"Visualización de Clusters usando PCA\")\n",
    "plt.xlabel(\"Componente Principal 1\")\n",
    "plt.ylabel(\"Componente Principal 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlación completa:\n",
      "                           runtime  popularity  voteAvg  voteCount  \\\n",
      "runtime                      1.000       0.519    0.474      0.550   \n",
      "popularity                   0.519       1.000    0.759      0.885   \n",
      "voteAvg                      0.474       0.759    1.000      0.784   \n",
      "voteCount                    0.550       0.885    0.784      1.000   \n",
      "genresAmount                 0.308       0.519    0.475      0.535   \n",
      "productionCoAmount           0.481       0.654    0.579      0.684   \n",
      "productionCountriesAmount    0.300       0.451    0.387      0.420   \n",
      "releaseYear                 -0.386      -0.544   -0.538     -0.666   \n",
      "\n",
      "                           genresAmount  productionCoAmount  \\\n",
      "runtime                           0.308               0.481   \n",
      "popularity                        0.519               0.654   \n",
      "voteAvg                           0.475               0.579   \n",
      "voteCount                         0.535               0.684   \n",
      "genresAmount                      1.000               0.456   \n",
      "productionCoAmount                0.456               1.000   \n",
      "productionCountriesAmount         0.277               0.483   \n",
      "releaseYear                      -0.371              -0.386   \n",
      "\n",
      "                           productionCountriesAmount  releaseYear  \n",
      "runtime                                        0.300       -0.386  \n",
      "popularity                                     0.451       -0.544  \n",
      "voteAvg                                        0.387       -0.538  \n",
      "voteCount                                      0.420       -0.666  \n",
      "genresAmount                                   0.277       -0.371  \n",
      "productionCoAmount                             0.483       -0.386  \n",
      "productionCountriesAmount                      1.000       -0.268  \n",
      "releaseYear                                   -0.268        1.000  \n"
     ]
    }
   ],
   "source": [
    "# Trabajamos con las variables originales (sin la columna Cluster)\n",
    "df_pca = df_cluster.drop(columns=['Cluster'])\n",
    "\n",
    "corr_matrix = df_pca.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(\n",
    "    corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "    center=0, vmin=-1, vmax=1, square=True,\n",
    "    linewidths=0.5, cbar_kws={'label': 'Correlación de Pearson'}\n",
    ")\n",
    "plt.title('Matriz de Correlación - Variables de Películas', fontsize=14, pad=15)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelación completa:\")\n",
    "print(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba KMO y Prueba de Esfericidad de Bartlett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prueba de KMO ===\n",
      "KMO Global: 0.8898\n",
      "\n",
      "KMO por variable:\n",
      "  runtime                            : 0.9681\n",
      "  popularity                         : 0.8559\n",
      "  voteAvg                            : 0.9512\n",
      "  voteCount                          : 0.8100\n",
      "  genresAmount                       : 0.9716\n",
      "  productionCoAmount                 : 0.9132\n",
      "  productionCountriesAmount          : 0.9101\n",
      "  releaseYear                        : 0.8698\n",
      "\n",
      "=== Prueba de Esfericidad de Bartlett ===\n",
      "Chi-cuadrado: 97505.58\n",
      "p-valor:      0.00e+00\n",
      "Resultado:    Se rechaza H0 - PCA es adecuado\n"
     ]
    }
   ],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "\n",
    "# KMO\n",
    "kmo_all, kmo_model = calculate_kmo(df_pca)\n",
    "print(\"=== Prueba de KMO ===\")\n",
    "print(f\"KMO Global: {kmo_model:.4f}\")\n",
    "print(\"\\nKMO por variable:\")\n",
    "for col, val in zip(df_pca.columns, kmo_all):\n",
    "    print(f\"  {col:35s}: {val:.4f}\")\n",
    "\n",
    "# Bartlett\n",
    "chi2, p = calculate_bartlett_sphericity(df_pca)\n",
    "print(f\"\\n=== Prueba de Esfericidad de Bartlett ===\")\n",
    "print(f\"Chi-cuadrado: {chi2:.2f}\")\n",
    "print(f\"p-valor:      {p:.2e}\")\n",
    "print(f\"Resultado:    {'Se rechaza H0 - PCA es adecuado' if p < 0.05 else 'No se rechaza H0'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Componentes Principales — Eigenvalores y Varianza Explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Eigenvalor  Varianza (%)  Varianza Acumulada (%)\n",
      "PC1      4.6444         58.05                   58.05\n",
      "PC2      0.8148         10.18                   68.24\n",
      "PC3      0.6928          8.66                   76.90\n",
      "PC4      0.6157          7.70                   84.59\n",
      "PC5      0.5026          6.28                   90.88\n",
      "PC6      0.3833          4.79                   95.67\n",
      "PC7      0.2522          3.15                   98.82\n",
      "PC8      0.0945          1.18                  100.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler_pca = StandardScaler()\n",
    "X_pca_scaled = scaler_pca.fit_transform(df_pca)\n",
    "\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_pca_scaled)\n",
    "\n",
    "eigenvalues = pca_full.explained_variance_\n",
    "variance_ratio = pca_full.explained_variance_ratio_\n",
    "cumulative = np.cumsum(variance_ratio)\n",
    "\n",
    "# Tabla resumen\n",
    "summary = pd.DataFrame({\n",
    "    'Eigenvalor': eigenvalues.round(4),\n",
    "    'Varianza (%)': (variance_ratio * 100).round(2),\n",
    "    'Varianza Acumulada (%)': (cumulative * 100).round(2)\n",
    "}, index=[f'PC{i+1}' for i in range(len(eigenvalues))])\n",
    "print(summary)\n",
    "\n",
    "# Scree plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Eigenvalores\n",
    "axes[0].bar(range(1, len(eigenvalues)+1), eigenvalues, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "axes[0].axhline(y=1, color='red', linestyle='--', linewidth=1.5, label='Criterio Kaiser (λ=1)')\n",
    "axes[0].set_xlabel('Componente Principal')\n",
    "axes[0].set_ylabel('Eigenvalor')\n",
    "axes[0].set_title('Scree Plot — Eigenvalores')\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks(range(1, len(eigenvalues)+1))\n",
    "\n",
    "# Varianza acumulada\n",
    "axes[1].plot(range(1, len(cumulative)+1), cumulative*100, marker='o', color='steelblue', linewidth=2)\n",
    "axes[1].axhline(y=70, color='orange', linestyle='--', label='70% varianza')\n",
    "axes[1].axhline(y=80, color='red', linestyle='--', label='80% varianza')\n",
    "axes[1].set_xlabel('Número de Componentes')\n",
    "axes[1].set_ylabel('Varianza Acumulada (%)')\n",
    "axes[1].set_title('Varianza Acumulada Explicada')\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(range(1, len(cumulative)+1))\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficientes (Cargas) de los Componentes Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargas (loadings) de los 3 componentes principales:\n",
      "                              PC1     PC2     PC3\n",
      "runtime                    0.3044  0.0009 -0.6476\n",
      "popularity                 0.4179 -0.0442  0.0129\n",
      "voteAvg                    0.3914 -0.1318  0.0037\n",
      "voteCount                  0.4325 -0.1532 -0.0289\n",
      "genresAmount               0.2978 -0.1370  0.7488\n",
      "productionCoAmount         0.3645  0.2958  0.0263\n",
      "productionCountriesAmount  0.2624  0.8071  0.0430\n",
      "releaseYear               -0.3196  0.4467  0.1283\n"
     ]
    }
   ],
   "source": [
    "# Cargas de los 3 primeros componentes\n",
    "n_components = 3\n",
    "loadings = pd.DataFrame(\n",
    "    pca_full.components_[:n_components].T,\n",
    "    index=df_pca.columns,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "print(\"Cargas (loadings) de los 3 componentes principales:\")\n",
    "print(loadings.round(4))\n",
    "\n",
    "# Heatmap de cargas\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    loadings, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "    center=0, vmin=-1, vmax=1, linewidths=0.5,\n",
    "    cbar_kws={'label': 'Carga'}\n",
    ")\n",
    "plt.title('Cargas de los Componentes Principales (PC1–PC3)', fontsize=13)\n",
    "plt.ylabel('Variable original')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Biplot PC1 vs PC2\n",
    "pca_3 = PCA(n_components=3)\n",
    "X_pca_3 = pca_3.fit_transform(X_pca_scaled)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(X_pca_3[:, 0], X_pca_3[:, 1], alpha=0.3, s=5, color='steelblue')\n",
    "\n",
    "scale = 3.5\n",
    "for i, var in enumerate(df_pca.columns):\n",
    "    plt.arrow(0, 0,\n",
    "              pca_3.components_[0, i] * scale,\n",
    "              pca_3.components_[1, i] * scale,\n",
    "              head_width=0.08, head_length=0.05, fc='red', ec='red')\n",
    "    plt.text(pca_3.components_[0, i] * scale * 1.15,\n",
    "             pca_3.components_[1, i] * scale * 1.15,\n",
    "             var, fontsize=9, color='darkred', ha='center')\n",
    "\n",
    "plt.xlabel(f'PC1 ({variance_ratio[0]*100:.1f}%)', fontsize=11)\n",
    "plt.ylabel(f'PC2 ({variance_ratio[1]*100:.1f}%)', fontsize=11)\n",
    "plt.title('Biplot PCA — PC1 vs PC2', fontsize=13)\n",
    "plt.axhline(0, color='gray', linewidth=0.5)\n",
    "plt.axvline(0, color='gray', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos para reglas de asociación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset para reglas: 19883 transacciones, 16 ítems\n",
      "\n",
      "Ítems disponibles: ['genresAmount_alto', 'genresAmount_bajo', 'genresAmount_medio', 'popularity_alto', 'popularity_bajo', 'popularity_medio', 'productionCoAmount_alto', 'productionCoAmount_bajo', 'productionCoAmount_medio', 'runtime_alto', 'runtime_bajo', 'runtime_medio', 'voteAvg_bajo', 'voteAvg_medio', 'voteCount_bajo', 'voteCount_medio']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Usamos las variables de características de película, excluyendo releaseYear y productionCountriesAmount\n",
    "df_assoc = df_cluster.drop(columns=['Cluster', 'releaseYear', 'productionCountriesAmount'])\n",
    "\n",
    "# Discretizar en 3 bins por cuantiles\n",
    "disc = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile', subsample=None)\n",
    "df_disc = pd.DataFrame(disc.fit_transform(df_assoc), columns=df_assoc.columns)\n",
    "\n",
    "labels = {0: 'bajo', 1: 'medio', 2: 'alto'}\n",
    "df_named = df_disc.copy()\n",
    "for col in df_named.columns:\n",
    "    df_named[col] = col + '_' + df_named[col].map(labels)\n",
    "\n",
    "# Encoding para mlxtend\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit_transform(df_named.values.tolist())\n",
    "df_onehot = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "print(f\"Dataset para reglas: {df_onehot.shape[0]} transacciones, {df_onehot.shape[1]} ítems\")\n",
    "print(\"\\nÍtems disponibles:\", list(df_onehot.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de parámetros de soporte y confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Soporte mín.  Confianza mín.  Itemsets frecuentes  Reglas generadas\n",
      "         0.30            0.80                   20                 7\n",
      "         0.30            0.75                   20                 9\n",
      "         0.30            0.70                   20                 9\n",
      "         0.25            0.80                   36                15\n",
      "         0.25            0.75                   36                23\n",
      "         0.25            0.70                   36                24\n",
      "         0.20            0.80                   61                30\n",
      "         0.20            0.75                   61                44\n",
      "         0.20            0.70                   61                51\n"
     ]
    }
   ],
   "source": [
    "# Prueba con distintos valores de soporte y confianza\n",
    "resultados = []\n",
    "for sup in [0.30, 0.25, 0.20]:\n",
    "    freq = apriori(df_onehot, min_support=sup, use_colnames=True)\n",
    "    for conf in [0.80, 0.75, 0.70]:\n",
    "        rules = association_rules(freq, metric='confidence', min_threshold=conf)\n",
    "        resultados.append({\n",
    "            'Soporte mín.': sup,\n",
    "            'Confianza mín.': conf,\n",
    "            'Itemsets frecuentes': len(freq),\n",
    "            'Reglas generadas': len(rules)\n",
    "        })\n",
    "\n",
    "print(pd.DataFrame(resultados).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        antecedents                   consequents  support  confidence    lift\n",
      "0                   voteCount_medio       productionCoAmount_alto   0.2799      0.8391  1.8450\n",
      "1                   popularity_bajo  voteAvg_bajo, voteCount_bajo   0.3105      0.9316  1.7492\n",
      "2                   popularity_alto       productionCoAmount_alto   0.2527      0.7579  1.6664\n",
      "3                      runtime_alto       productionCoAmount_alto   0.2514      0.7416  1.6305\n",
      "4                   popularity_bajo                voteCount_bajo   0.3332      1.0000  1.5005\n",
      "5           productionCoAmount_bajo                voteCount_bajo   0.2636      1.0000  1.5005\n",
      "6     popularity_bajo, voteAvg_bajo                voteCount_bajo   0.3105      1.0000  1.5005\n",
      "7                   voteCount_medio             genresAmount_alto   0.2891      0.8667  1.4881\n",
      "8                      runtime_bajo  voteAvg_bajo, voteCount_bajo   0.2590      0.7888  1.4809\n",
      "9        runtime_bajo, voteAvg_bajo                voteCount_bajo   0.2590      0.9722  1.4588\n",
      "10                  popularity_alto             genresAmount_alto   0.2771      0.8311  1.4270\n",
      "11                  popularity_bajo                  voteAvg_bajo   0.3105      0.9316  1.4150\n",
      "12  popularity_bajo, voteCount_bajo                  voteAvg_bajo   0.3105      0.9316  1.4150\n",
      "13                     runtime_bajo                voteCount_bajo   0.3033      0.9239  1.3863\n",
      "14                     runtime_alto             genresAmount_alto   0.2672      0.7880  1.3530\n",
      "15                    voteAvg_medio             genresAmount_alto   0.2690      0.7874  1.3520\n",
      "16          productionCoAmount_alto             genresAmount_alto   0.3563      0.7834  1.3451\n",
      "17     runtime_bajo, voteCount_bajo                  voteAvg_bajo   0.2590      0.8538  1.2967\n",
      "18               genresAmount_medio                voteCount_bajo   0.2761      0.8613  1.2924\n",
      "19                     runtime_bajo                  voteAvg_bajo   0.2664      0.8113  1.2322\n",
      "20                     voteAvg_bajo                voteCount_bajo   0.5326      0.8090  1.2138\n",
      "21                   voteCount_bajo                  voteAvg_bajo   0.5326      0.7992  1.2138\n",
      "22               genresAmount_medio                  voteAvg_bajo   0.2514      0.7844  1.1914\n",
      "23                    runtime_medio                  voteAvg_bajo   0.2531      0.7610  1.1558\n"
     ]
    }
   ],
   "source": [
    "# Generación final de reglas\n",
    "freq_items = apriori(df_onehot, min_support=0.25, use_colnames=True)\n",
    "rules = association_rules(freq_items, metric='confidence', min_threshold=0.70)\n",
    "rules = rules.sort_values(['lift', 'confidence'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(sorted(x)))\n",
    "rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(sorted(x)))\n",
    "\n",
    "display_cols = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "print(rules[display_cols].round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 reglas por Lift:\n",
      "                  antecedents                  consequents  support  confidence   lift\n",
      "              voteCount_medio      productionCoAmount_alto   0.2799      0.8391 1.8450\n",
      "              popularity_bajo voteAvg_bajo, voteCount_bajo   0.3105      0.9316 1.7492\n",
      "              popularity_alto      productionCoAmount_alto   0.2527      0.7579 1.6664\n",
      "                 runtime_alto      productionCoAmount_alto   0.2514      0.7416 1.6305\n",
      "              popularity_bajo               voteCount_bajo   0.3332      1.0000 1.5005\n",
      "      productionCoAmount_bajo               voteCount_bajo   0.2636      1.0000 1.5005\n",
      "popularity_bajo, voteAvg_bajo               voteCount_bajo   0.3105      1.0000 1.5005\n",
      "              voteCount_medio            genresAmount_alto   0.2891      0.8667 1.4881\n",
      "                 runtime_bajo voteAvg_bajo, voteCount_bajo   0.2590      0.7888 1.4809\n",
      "   runtime_bajo, voteAvg_bajo               voteCount_bajo   0.2590      0.9722 1.4588\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sc = plt.scatter(\n",
    "    rules['support'], rules['confidence'],\n",
    "    c=rules['lift'], cmap='YlOrRd', s=80, edgecolors='gray', linewidths=0.5\n",
    ")\n",
    "plt.colorbar(sc, label='Lift')\n",
    "plt.xlabel('Soporte', fontsize=12)\n",
    "plt.ylabel('Confianza', fontsize=12)\n",
    "plt.title('Reglas de Asociación — Soporte vs Confianza (color = Lift)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 10 por lift\n",
    "print(\"\\nTop 10 reglas por Lift:\")\n",
    "print(rules[display_cols].head(10).round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Otros Algoritmos de Aprendizaje No Supervisado — DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eps  min_samples   Clusters    Ruido   % Ruido   Silhouette\n",
      "-----------------------------------------------------------------\n",
      "  0.8           50         14     4961     25.0%       0.1027\n",
      "  0.8          100          9     7105     35.7%       0.1612\n",
      "  1.0           50          5     1842      9.3%       0.1890\n",
      "  1.0          100          4     2965     14.9%       0.2217\n",
      "  1.2           50          3      649      3.3%       0.1249\n",
      "  1.2          100          3     1188      6.0%       0.1719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "print(f\"{'eps':>5} {'min_samples':>12} {'Clusters':>10} {'Ruido':>8} {'% Ruido':>9} {'Silhouette':>12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for eps in [0.8, 1.0, 1.2]:\n",
    "    for ms in [50, 100]:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        labels_db = db.fit_predict(X_scaled)\n",
    "        n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        n_noise = (labels_db == -1).sum()\n",
    "        pct_noise = n_noise / len(labels_db) * 100\n",
    "        if n_clusters >= 2:\n",
    "            mask = labels_db != -1\n",
    "            sil = silhouette_score(X_scaled[mask], labels_db[mask])\n",
    "            print(f\"{eps:>5} {ms:>12} {n_clusters:>10} {n_noise:>8} {pct_noise:>8.1f}% {sil:>12.4f}\")\n",
    "        else:\n",
    "            print(f\"{eps:>5} {ms:>12} {n_clusters:>10} {n_noise:>8} {pct_noise:>8.1f}%   {'N/A':>12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clusters DBSCAN:\n",
      "  Ruido: 2965 películas (14.9%)\n",
      "  Cluster 0: 2484 películas (12.5%)\n",
      "  Cluster 1: 2256 películas (11.3%)\n",
      "  Cluster 2: 11460 películas (57.6%)\n",
      "  Cluster 3: 718 películas (3.6%)\n",
      "\n",
      "Silhouette Score (sin ruido): 0.2217\n"
     ]
    }
   ],
   "source": [
    "db_final = DBSCAN(eps=1.0, min_samples=100)\n",
    "labels_db = db_final.fit_predict(X_scaled)\n",
    "\n",
    "df_pca['DBSCAN'] = labels_db\n",
    "\n",
    "# Distribución de clusters\n",
    "counts = pd.Series(labels_db).value_counts().sort_index()\n",
    "print(\"Distribución de clusters DBSCAN:\")\n",
    "for idx, cnt in counts.items():\n",
    "    label = 'Ruido' if idx == -1 else f'Cluster {idx}'\n",
    "    print(f\"  {label}: {cnt} películas ({cnt/len(labels_db)*100:.1f}%)\")\n",
    "\n",
    "mask = labels_db != -1\n",
    "sil_db = silhouette_score(X_scaled[mask], labels_db[mask])\n",
    "print(f\"\\nSilhouette Score (sin ruido): {sil_db:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfiles medios por cluster DBSCAN:\n",
      "        runtime  popularity  voteAvg  voteCount  genresAmount  \\\n",
      "DBSCAN                                                          \n",
      "0        52.397       0.075    0.100      0.022         0.939   \n",
      "1        44.508       0.088    0.082      0.016         1.007   \n",
      "2        91.239       2.383    4.878      4.328         2.231   \n",
      "3        48.414       0.110    0.008      0.009         1.444   \n",
      "\n",
      "        productionCoAmount  productionCountriesAmount  releaseYear  \n",
      "DBSCAN                                                              \n",
      "0                    0.000                      0.000     2025.254  \n",
      "1                    0.000                      0.726     2025.228  \n",
      "2                    1.183                      0.778     2014.766  \n",
      "3                    0.772                      0.000     2025.234  \n"
     ]
    }
   ],
   "source": [
    "# Perfiles de cada cluster\n",
    "print(\"Perfiles medios por cluster DBSCAN:\")\n",
    "profile = df_pca[df_pca['DBSCAN'] != -1].groupby('DBSCAN').mean()\n",
    "print(profile.drop(columns=['DBSCAN'], errors='ignore').round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización DBSCAN con PCA 2D\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "palette = {-1: 'lightgray', 0: '#e41a1c', 1: '#377eb8', 2: '#4daf4a', 3: '#984ea3', 4: '#ff7f00'}\n",
    "cluster_names = {-1: 'Ruido', 0: 'Cluster 0', 1: 'Cluster 1', 2: 'Cluster 2', 3: 'Cluster 3'}\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for cluster_id in sorted(set(labels_db)):\n",
    "    mask_c = labels_db == cluster_id\n",
    "    alpha = 0.15 if cluster_id == -1 else 0.5\n",
    "    size = 3 if cluster_id == -1 else 8\n",
    "    plt.scatter(\n",
    "        X_2d[mask_c, 0], X_2d[mask_c, 1],\n",
    "        c=palette.get(cluster_id, 'black'),\n",
    "        label=cluster_names.get(cluster_id, f'Cluster {cluster_id}'),\n",
    "        s=size, alpha=alpha\n",
    "    )\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "plt.title('DBSCAN — Visualización en espacio PCA 2D\\n(eps=1.0, min_samples=100)', fontsize=13)\n",
    "plt.legend(markerscale=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación DBSCAN vs K-Means\n",
    "df_pca['KMeans'] = clusters\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# KMeans\n",
    "for c in sorted(df_pca['KMeans'].unique()):\n",
    "    mask_c = df_pca['KMeans'] == c\n",
    "    axes[0].scatter(X_2d[mask_c, 0], X_2d[mask_c, 1], label=f'Cluster {c}', s=5, alpha=0.4)\n",
    "axes[0].set_title('K-Means (K=3)', fontsize=12)\n",
    "axes[0].set_xlabel('PC1'); axes[0].set_ylabel('PC2')\n",
    "axes[0].legend(markerscale=3)\n",
    "\n",
    "# DBSCAN\n",
    "for cluster_id in sorted(set(labels_db)):\n",
    "    mask_c = labels_db == cluster_id\n",
    "    alpha = 0.1 if cluster_id == -1 else 0.4\n",
    "    size = 3 if cluster_id == -1 else 6\n",
    "    lbl = 'Ruido' if cluster_id == -1 else f'Cluster {cluster_id}'\n",
    "    axes[1].scatter(X_2d[mask_c, 0], X_2d[mask_c, 1], \n",
    "                    c=palette.get(cluster_id, 'black'), label=lbl, s=size, alpha=alpha)\n",
    "axes[1].set_title('DBSCAN (eps=1.0, min_samples=100)', fontsize=12)\n",
    "axes[1].set_xlabel('PC1'); axes[1].set_ylabel('PC2')\n",
    "axes[1].legend(markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
